{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "480eac2f402e053e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:21.615623Z",
     "start_time": "2024-06-07T16:07:21.611215Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "# Ignore specific UserWarnings related to max_length in transformers\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "    message=\".*Using the model-agnostic default `max_length`.*\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "class DummyModel(nn.Module):\n",
    "  \"\"\"\n",
    "  A dummy model that consists of an embedding layer\n",
    "  with two blocks of a linear layer followed by a layer\n",
    "  norm layer.\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "    self.token_embedding = nn.Embedding(2, 2)\n",
    "\n",
    "    # Block 1\n",
    "    self.linear_1 = nn.Linear(2, 2)\n",
    "    self.layernorm_1 = nn.LayerNorm(2)\n",
    "\n",
    "    # Block 2\n",
    "    self.linear_2 = nn.Linear(2, 2)\n",
    "    self.layernorm_2 = nn.LayerNorm(2)\n",
    "\n",
    "    self.head = nn.Linear(2, 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    hidden_states = self.token_embedding(x)\n",
    "\n",
    "    # Block 1\n",
    "    hidden_states = self.linear_1(hidden_states)\n",
    "    hidden_states = self.layernorm_1(hidden_states)\n",
    "\n",
    "    # Block 2\n",
    "    hidden_states = self.linear_2(hidden_states)\n",
    "    hidden_states = self.layernorm_2(hidden_states)\n",
    "\n",
    "    logits = self.head(hidden_states)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def get_generation(model, processor, image, dtype):\n",
    "  inputs = processor(image, return_tensors=\"pt\").to(dtype)\n",
    "  out = model.generate(**inputs)\n",
    "  return processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def load_image(img_url):\n",
    "    image = Image.open(requests.get(\n",
    "        img_url, stream=True).raw).convert('RGB')\n",
    "\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:21.707489Z",
     "start_time": "2024-06-07T16:07:21.695980Z"
    }
   },
   "id": "initial_id",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DummyModel(\n  (token_embedding): Embedding(2, 2)\n  (linear_1): Linear(in_features=2, out_features=2, bias=True)\n  (layernorm_1): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n  (linear_2): Linear(in_features=2, out_features=2, bias=True)\n  (layernorm_2): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n  (head): Linear(in_features=2, out_features=2, bias=True)\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DummyModel()\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:21.807415Z",
     "start_time": "2024-06-07T16:07:21.736279Z"
    }
   },
   "id": "8877dd652bd21c99",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embedding.weight is loaded in torch.float32\n",
      "linear_1.weight is loaded in torch.float32\n",
      "linear_1.bias is loaded in torch.float32\n",
      "layernorm_1.weight is loaded in torch.float32\n",
      "layernorm_1.bias is loaded in torch.float32\n",
      "linear_2.weight is loaded in torch.float32\n",
      "linear_2.bias is loaded in torch.float32\n",
      "layernorm_2.weight is loaded in torch.float32\n",
      "layernorm_2.bias is loaded in torch.float32\n",
      "head.weight is loaded in torch.float32\n",
      "head.bias is loaded in torch.float32\n"
     ]
    }
   ],
   "source": [
    "def print_param_dtype(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name} is loaded in {param.dtype}\")\n",
    "      \n",
    "print_param_dtype(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:21.814988Z",
     "start_time": "2024-06-07T16:07:21.809432Z"
    }
   },
   "id": "d219f37079628a6e",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above code a dummy neural network model is created. It consists of an embedding layer, followed by two blocks of a linear layer + normalization layer. It concludes with a linear output.\n",
    "\n",
    "All of the layers are clearly in the float32 datatype."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e1ba242a9a555ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_fp16 = model.half() #fp16\n",
    "# model_bf16 = model.bfloat16() #bf16"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:21.827416Z",
     "start_time": "2024-06-07T16:07:21.818014Z"
    }
   },
   "id": "5e71dcd86d034c13",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embedding.weight is loaded in torch.float16\n",
      "linear_1.weight is loaded in torch.float16\n",
      "linear_1.bias is loaded in torch.float16\n",
      "layernorm_1.weight is loaded in torch.float16\n",
      "layernorm_1.bias is loaded in torch.float16\n",
      "linear_2.weight is loaded in torch.float16\n",
      "linear_2.bias is loaded in torch.float16\n",
      "layernorm_2.weight is loaded in torch.float16\n",
      "layernorm_2.bias is loaded in torch.float16\n",
      "head.weight is loaded in torch.float16\n",
      "head.bias is loaded in torch.float16\n"
     ]
    }
   ],
   "source": [
    "print_param_dtype(model_fp16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:21.864524Z",
     "start_time": "2024-06-07T16:07:21.858208Z"
    }
   },
   "id": "c3d08b377b1edc58",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model can be easily converted to a lower datatype using the functions available in pytorch. Here we halved the precision of the float type."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "605a7b148c1ca687"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dummy_input = torch.LongTensor([[1, 0], [0, 1]])  # LongTensor is a 64-bit integer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:21.910629Z",
     "start_time": "2024-06-07T16:07:21.905821Z"
    }
   },
   "id": "1edd52c1fad5aa0d",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.6870,  0.7134],\n         [-0.6870,  0.7134]],\n\n        [[-0.6870,  0.7134],\n         [-0.6870,  0.7134]]], dtype=torch.float16, grad_fn=<ViewBackward0>)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_fp32 = model(dummy_input)\n",
    "logits_fp32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:21.984054Z",
     "start_time": "2024-06-07T16:07:21.973938Z"
    }
   },
   "id": "9c9bb237c42781bf",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.6870,  0.7134],\n         [-0.6870,  0.7134]],\n\n        [[-0.6870,  0.7134],\n         [-0.6870,  0.7134]]], dtype=torch.float16, grad_fn=<ViewBackward0>)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_fp16 = model_fp16(dummy_input)\n",
    "logits_fp16"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:22.020931Z",
     "start_time": "2024-06-07T16:07:22.008774Z"
    }
   },
   "id": "358f2375d91d48f4",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vision_model.embeddings.class_embedding is loaded in torch.float32\n",
      "vision_model.embeddings.position_embedding is loaded in torch.float32\n",
      "vision_model.embeddings.patch_embedding.weight is loaded in torch.float32\n",
      "vision_model.embeddings.patch_embedding.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.0.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.1.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.2.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.3.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.4.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.5.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.6.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.7.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.8.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.9.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.10.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.self_attn.qkv.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.self_attn.qkv.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.self_attn.projection.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.self_attn.projection.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.layer_norm1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.layer_norm1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.mlp.fc1.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.mlp.fc1.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.mlp.fc2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.mlp.fc2.bias is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.layer_norm2.weight is loaded in torch.float32\n",
      "vision_model.encoder.layers.11.layer_norm2.bias is loaded in torch.float32\n",
      "vision_model.post_layernorm.weight is loaded in torch.float32\n",
      "vision_model.post_layernorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.embeddings.word_embeddings.weight is loaded in torch.float32\n",
      "text_decoder.bert.embeddings.position_embeddings.weight is loaded in torch.float32\n",
      "text_decoder.bert.embeddings.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.embeddings.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.0.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.1.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.2.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.3.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.4.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.5.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.6.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.7.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.8.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.9.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.10.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.attention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.self.query.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.self.query.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.self.key.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.self.key.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.self.value.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.self.value.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.intermediate.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.intermediate.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.output.dense.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.output.dense.bias is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.output.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.bert.encoder.layer.11.output.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.cls.predictions.bias is loaded in torch.float32\n",
      "text_decoder.cls.predictions.transform.dense.weight is loaded in torch.float32\n",
      "text_decoder.cls.predictions.transform.dense.bias is loaded in torch.float32\n",
      "text_decoder.cls.predictions.transform.LayerNorm.weight is loaded in torch.float32\n",
      "text_decoder.cls.predictions.transform.LayerNorm.bias is loaded in torch.float32\n",
      "text_decoder.cls.predictions.decoder.weight is loaded in torch.float32\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipForConditionalGeneration\n",
    "\n",
    "model_name = \"Salesforce/blip-image-captioning-base\"\n",
    "model = BlipForConditionalGeneration.from_pretrained(model_name)\n",
    "print_param_dtype(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:25.898551Z",
     "start_time": "2024-06-07T16:07:22.041790Z"
    }
   },
   "id": "a5161b7a01cca172",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "989660400"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footprint_fp32 = model.get_memory_footprint()\n",
    "footprint_fp32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:25.908724Z",
     "start_time": "2024-06-07T16:07:25.900570Z"
    }
   },
   "id": "1d363f422c7624ef",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "494832248"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fp16 = BlipForConditionalGeneration.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "footprint_fp16 = model_fp16.get_memory_footprint()\n",
    "footprint_fp16"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:27.339566Z",
     "start_time": "2024-06-07T16:07:25.910742Z"
    }
   },
   "id": "754975f0348b8bd7",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Footprint of fp16 dtype is 1.9999917224x smaller\n"
     ]
    }
   ],
   "source": [
    "print(f\"Footprint of fp16 dtype is {footprint_fp32 / footprint_fp16:.10f}x smaller\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:07:49.271129Z",
     "start_time": "2024-06-07T16:07:49.266131Z"
    }
   },
   "id": "9f1bcbe1ef28ed12",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "Models can be downcast as well by simply loading them using a smaller datatype. Here we downcast the model to fp16 from fp32."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40d0470ec66b872f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "desired_dtype = torch.bfloat16\n",
    "torch.set_default_dtype(desired_dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:08:39.421564Z",
     "start_time": "2024-06-07T16:08:39.416461Z"
    }
   },
   "id": "f93b8f7aaad219a7",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embedding.weight is loaded in torch.bfloat16\n",
      "linear_1.weight is loaded in torch.bfloat16\n",
      "linear_1.bias is loaded in torch.bfloat16\n",
      "layernorm_1.weight is loaded in torch.bfloat16\n",
      "layernorm_1.bias is loaded in torch.bfloat16\n",
      "linear_2.weight is loaded in torch.bfloat16\n",
      "linear_2.bias is loaded in torch.bfloat16\n",
      "layernorm_2.weight is loaded in torch.bfloat16\n",
      "layernorm_2.bias is loaded in torch.bfloat16\n",
      "head.weight is loaded in torch.bfloat16\n",
      "head.bias is loaded in torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "dummy_model_bf16 = DummyModel()\n",
    "print_param_dtype(dummy_model_bf16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T16:08:49.838793Z",
     "start_time": "2024-06-07T16:08:49.830782Z"
    }
   },
   "id": "e52a753db5724d7f",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also set the default preferred datatype using the `torch.set_default_dtype` function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "720694034cec547c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
